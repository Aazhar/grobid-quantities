<text xmlns="http://www.tei-c.org/ns/1.0">
	<p>An allergy is an abnormal reaction of the immune system towards foreign substances (allergens) that are normally harmless. Peanut allergies in particular affect more than <measure type="interval" ptr="#1ca6a599-216e-42d1-a1c9-d91a3a9030d0">0.5</measure><quantifiedObject id="1ca6a599-216e-42d1-a1c9-d91a3a9030d0">% of</quantifiedObject> the entire French population, and its increasing prevalence and potentially severe clinical reactions make it a public health problem. It is also the most lethal food allergy [4]. Following a strict avoidance diet is currently the only effective treatment that minimises potentially lethal accidents.</p>
	<p>• Score 1: Mild symptoms among <quantifiedObject id="0a5b0393-60fa-4af9-9d4c-bbb2f9fc2964">: abdominal pains</quantifiedObject> that spontaneously resolve under <measure type="interval" ptr="#0a5b0393-60fa-4af9-9d4c-bbb2f9fc2964">30 minutes</measure> and/or rhinocunjunctivitis and/or <quantifiedObject id="2b67c24a-611b-4361-a22f-0261ef7d9aca">urticaria</quantifiedObject> &lt; <measure type="interval" ptr="#2b67c24a-611b-4361-a22f-0261ef7d9aca">10</measure> papulas and/or a rash (eczema onset);</p>
	<p>• Score 2: <measure type="value">One</measure> moderate symptom among : <quantifiedObject id="5887b742-dc55-4dd1-ad1a-73cc0ca3d8b7">abdominal pain requiring</quantifiedObject> treatment or generalized urticaria or non-laryngeal angioedema or cough or fall of Peak Expiratory Flow between <measure type="interval" ptr="#5887b742-dc55-4dd1-ad1a-73cc0ca3d8b7">15 and 20%</measure>;</p>
	<p>• Score 3: <measure type="value">Two</measure> moderate symptoms in the preceding list;</p>
	<p>• Score 4: <measure type="value">Three</measure> moderate symptoms in the preceding list or laryngeal oedema or hypotension or asthma requiring treatment;</p>
	<p>A clinical study was performed using <measure type="value" ptr="#5dc2dbe6-b758-462e-8a0c-067f63351fc2">76</measure> <quantifiedObject id="5dc2dbe6-b758-462e-8a0c-067f63351fc2">allergic patients with</quantifiedObject> <quantifiedObject id="16c16e48-33e2-4eee-aa7f-56ac518fc980">ages from</quantifiedObject> <measure type="interval" ptr="#16c16e48-33e2-4eee-aa7f-56ac518fc980">3 to 18 years</measure>. Tables 1 and 2 describe the frequencies observed for DBPCFC score, the first accidental exposure score and the eliciting dose. Note that only <measure type="value">47 out of the 76</measure> patients experienced a first accident. The remaining <measure type="value" ptr="#a7c55195-e0d6-4c8b-a546-546f051d6809">29</measure> <quantifiedObject id="a7c55195-e0d6-4c8b-a546-546f051d6809">patients</quantifiedObject> were diagnosed during an allergy check-up and subsequently confirmed by DBPCFC, thus avoiding further accidents. Patients were homogeneously distributed in age and sex across severity scores. <measure type="value" ptr="#1ca255ef-3d93-4a3e-8d87-3b964b2528d6">Thirty-four</measure> <quantifiedObject id="1ca255ef-3d93-4a3e-8d87-3b964b2528d6">variables</quantifiedObject> were measured to reveal the presence of Immunoglobulins of type E (IgE) antibodies. These are proteins produced by the immune system that can elicit allergic reactions [20]. Each antibody is specific to an allergen, i.e., it is coded to identify a particular protein for elimination. We measured the levels of IgE for the proteins of interest with the goal of building a predictive model of allergy severity. The variables used to test for IgE were measured either by immunoassays or by Skin Prick Tests (SPTs).</p>
	<p>Immunoassays are biochemical tests that quantify the level of antibodies in a blood sample (in kilo-units per liter ). We performed <measure type="value" ptr="#f3f7e857-f99c-4774-a810-56aeabea1a3f">six</measure> <quantifiedObject id="f3f7e857-f99c-4774-a810-56aeabea1a3f">immunoassays aimed</quantifiedObject> at measuring the following: the total IgE, the specific IgE to peanut (f13), and the specific IgE to recombinant (r)Ara-h1, rAra-h2, rAra-h3, rAra-h8, which are IgE especially directed against peanut recombinant major allergens [1].</p>
	<p>SPTs are used to detect an immunological sensitivity to a particular substance. They show the functional aspect of cellular IgE, which are linked to mast cells releasing chemical mediators that elicit symptoms [20]. A small dose of allergen is applied under the skin by pricking with a needle, and the diameter of the resulting wheal is measured in millimeters. We also measured the diameter of prick-tests to codeine as a positive control showing the basal reactivity of the skin. The ratio of the <measure type="value" ptr="#99d246c5-4783-4e74-8781-941190affeb0">two</measure> <quantifiedObject id="99d246c5-4783-4e74-8781-941190affeb0">diameters</quantifiedObject> is used to measure the allergen reaction.</p>
	<p>We performed prick-tests for <measure type="value" ptr="#1c4f031f-7e4e-470a-9e68-411c047b0459">28</measure> <quantifiedObject id="1c4f031f-7e4e-470a-9e68-411c047b0459">allergens divided</quantifiedObject> into <measure type="value" ptr="#dc4a7403-b22c-455f-abd0-497e8f961c71">three</measure> <quantifiedObject id="dc4a7403-b22c-455f-abd0-497e8f961c71">families</quantifiedObject>:</p>
	<p>1. <measure type="value">11</measure> nuts: almond, Brazil nut, cashew nut, chestnut, hazelnut, peanut, pecan nut, pine nut, pistachio, Queensland nut, walnut, which are often related to peanut allergies by cross-reactivity;</p>
	<p>3. <measure type="value" ptr="#0e14a130-dbed-44b8-a397-0947f573d52d">10</measure> <quantifiedObject id="0e14a130-dbed-44b8-a397-0947f573d52d">aeroallergens</quantifiedObject>: <measure type="value">12</measure> grass pollens, Alternaria, ash, birch, cat epithelia, dog epithelia, Dpte (Dermatophago¨ıdesDermatophago¨ıdes pteronyssinus), mugwort, ribwort, rape seed, which are the common clinical allergens.</p>
	<p>To solve our problems, discriminant analyses of DBPCFC score, first accident score and eliciting dose were performed by using several classifiers. <measure type="value" ptr="#c8c89532-44da-4750-92a0-ec06af6719f6">Two</measure> <quantifiedObject id="c8c89532-44da-4750-92a0-ec06af6719f6">studies</quantifiedObject> were performed for each measure of severity by treating it as a <measure type="value">four</measure>-class variable, and then as a <measure type="value">two</measure>-class variable. For DBPCFC and first accidental exposure, <measure type="value" ptr="#1da3fbe0-699f-4d41-b620-89b9e978d4b3">4</measure> <quantifiedObject id="1da3fbe0-699f-4d41-b620-89b9e978d4b3">classes</quantifiedObject> were built by considering the score groups {1}, {2}, {3} and {4, 5} because of the low frequency of score 5. For the <measure type="value" ptr="#d70c62d9-271a-47a7-9019-a1aebf906636">two</measure>-<quantifiedObject id="d70c62d9-271a-47a7-9019-a1aebf906636">class discrimination</quantifiedObject>, groups were formed by scores of either {1, 2, 3} or {4, 5}, as recommended by clinicians. Since eliciting dose values are fixed by levels by the clinician [1], its measure is not a continuous variable and cannot be predicted by a regression analysis. Moreover although eliciting dose could be considered as a class variable, a discriminant analysis cannot be directly performed because of numerous categories with low frequencie (Table 2). A first solution consisted in converting eliciting dose into a <measure type="list">fourtwo</measure> or -class variable by searching the best discriminated classification computed with all available variables. A second solution will be proposed in Section 3.3. Careful variable selection appeared especially as a major point of the analysis. Therefore <measure type="value">three</measure> different statistical approaches were proposed for each measure of severity :</p>
	<p>The performances of several classification rules were first compared without preselecting variables. Linear Discriminant Analysis (LDA), k-Nearest Neighbors (k−NN), Classification And Regression Trees (CART) [10] and AdaBoost with CART [5] were performed using all the <measure type="value" ptr="#0e04fc07-23e4-4e4c-8395-1345ec2de174">34</measure> <quantifiedObject id="0e04fc07-23e4-4e4c-8395-1345ec2de174">available variables as</quantifiedObject> predictors. k−NN were performed for k ∈ {1, . . . , 5} and the number of nearest neighbors giving the best results was kept.</p>
	<p>Since in supervised learning keeping noisy predictors can increase the misclassification error, <measure type="value" ptr="#cfef9c9c-db55-48d9-b258-77a528c571e3">two</measure> <quantifiedObject id="cfef9c9c-db55-48d9-b258-77a528c571e3">methods</quantifiedObject> that simulteanously perform variable selection and classification were also used : stepwise logistic regression [11] and penalized SVM [2].</p>
	<p>As explained earlier, the determination of a set of predictors to keep is one of the main points of the study. Thus a variable selection scheme independent from classification was also developed. Variables were retained in the model if either the corresponding p-value of the Kruskal-Wallis test [6] was smaller than <measure type="interval">0.10</measure>, or if the variable was selected by the stepwise Wilks' lambda (Λ) criterion [13]. The Λ statistic was computed at each step with all variables already present in the model, whereas the F − to − enter statistic and corresponding p-value measure the discriminant power of a variable added to the preceding ones. For the latter, the maximal F − to − enter p-values used as entry and removal criteria were set by default to <measure type="value">0.15</measure>, as recommended by [7]. The nonparametric Kruskal-Wallis test was preferred to ANOVA, because variables were not always normally distributed in the classes induced by the scores. Note that the Wilks' lambda selection is based on the hypotheses of multi-normality of the variables vector distribution and equality of the within-class covariance matrices. In 1975, Lachenbruch [14] asserted that the F −test is robust to small deviations of these hypotheses. We therefore decided to use the Wilks' lambda selection even though variables were not always normally distributed in the classes induced by the measures of severity. This variable selection scheme is a compromise between the assessment of variable marginal importance and the detection of a discriminant subset of predictors. This will allow first to provide biologists and allergists a list of informative variables in regards to the mechanisms involved in allergic reactions, and second to avoid keeping noisy variables that could degrade the performance of the learning algorithms. Biologists and allergists are particularly interested in using immunoassays as markers of the severity of peanut allergy because Specific IgE to rAra-h1, rAra-h2, rAra-h3 are yet known to be very useful in practice to detect peanut allergic patients [1]. Moreover immunoassays are precise and reliable measures contrary to SPTs. But the number of discriminant SPTs can far exceed the number of selected immunoassays, which could possibly smear out the signal brought by immunoassays. As we wanted nevertheless to keep the information provided by SPTs, a Multiple Factorial Analysis (MFA) [8] was performed to equalize the influence of both groups of selected variables, which enabled the use of factors as new predictors of severity. Thus we performed <measure type="value">two</measure> discriminant analyses :</p>
	<p>To discriminate this variable, we also devised an algorithm that simultaneously clusters the eliciting dose values and selects predictors by minimizing the Wilks' lambda (Section 3.3). This algorithm was applied by using raw variables or factors computed by MFA with the <measure type="value" ptr="#2956b6e1-7864-497a-95ba-c761e97800e9">34</measure> <quantifiedObject id="2956b6e1-7864-497a-95ba-c761e97800e9">available variables as</quantifiedObject> predictors. Once the predictors were chosen and the clusters built, the same statistical approaches as for DBPCFC and first accident scores were used. The corresponding statistical analysis is summarized in Figure 2.</p>
	<p>with q k=<measure type="value">1</measure> m k =p, where m k is the number of variables in group k. Denote X k the matrix of data of size n × p corresponding to the k th group of variables, namely :</p>
	<p>n where the generic element x k,j i denotes the measure of the variable x k,j for the sample point i. Let also X = (X 1 | . . . |X q ) be the matrix corresponding to the whole set of variables. For the k th group of variables, let M k be a metric matrix in <quantifiedObject id="158224dc-b5cd-4be8-a024-ae708c12b6b1">R m k ,</quantifiedObject> k=<measure type="value" ptr="#158224dc-b5cd-4be8-a024-ae708c12b6b1">1</measure>, . . . , q. Let D be the diagonal matrix of the weights assigned to the sample points. The MFA algorithm is then as follows :</p>
	<p>Note that in our case, q = <measure type="value">2</measure> with the immunoassays as the first group of variables and the SPTs as the second. Variables were first centered and scaled to unity, and the metric matrix M k was then set to the identity matrix I k in R m k . For the DBPCFC and first accident scores, we thought it made more sense to compute the factors using only the discriminant variables rather than using all available variables. Indeed, the predictive model needed to be built with a reasonable number of characters. Even if a limited number of factors were chosen afterwards, all variables would still have to be measured to compute the factors. Moreover, a non-discriminant variable could have a large coefficient for some retained factors even though it would not improve the overall discriminative power of the model. Nonetheless, we did compute factors using all variables as well, but the results did not improve the discrimination of the first accident score. For the eliciting dose, factors were computed using all <measure type="value" ptr="#4968fa74-b4d0-465d-ac14-a05d13c85e74">34</measure> <quantifiedObject id="4968fa74-b4d0-465d-ac14-a05d13c85e74">available variables</quantifiedObject>, not only the discriminant ones. As described in Section 3.3, the set of discriminant variables depends on the choice of the clustering of eliciting dose values and vice versa. Thus it did not seem appropriate to replace the optimal set of variables by factors.</p>
	<p>Here we propose an algorithm to perform these <measure type="value" ptr="#a3516e9b-f97f-4af3-b08f-de32783a4150">two</measure> <quantifiedObject id="a3516e9b-f97f-4af3-b08f-de32783a4150">steps</quantifiedObject> simultaneously using alternate optimization.</p>
	<p>Since Wilks' lambda provides a non-empirical stopping rule by testing its significance, this approach was preferred over using within-class inertia computation as the optimality criterion. The p-value of F − to − enter was set to <measure type="value">0.15</measure>.</p>
	<p>1. choose the clustering C 1 of eliciting dose values that minimises Λ, computed using all <measure type="value">34</measure> available predictors ;</p>
	<p>• procedure stops if either no left predictor can improve the discriminant power of the model, i.e., if F − to − enter p−value is greater than <measure type="interval">0.15</measure> [13], or if every predictor is already entered.</p>
	<p>Note that the F −to−enter value is only computed when a new variable is entered into the model. This algorithm was used with both the variables and the MFA factors computed using all <measure type="value" ptr="#11b0dd70-46da-4f36-9138-413fc0eb312e">34</measure> <quantifiedObject id="11b0dd70-46da-4f36-9138-413fc0eb312e">available variables</quantifiedObject>. Since new discriminant variables could have been chosen at each step of the algorithm, there was no default starting set of discriminant variables. Moreover, it did not seem appropriate to perform the MFA at the end of the algorithm, since the selected variables were specifically chosen to discriminate the found clusters.</p>
	<p>Linear discriminant analysis, k-NN, CART [10] and stepwise logistic regression [11] are classic methods. For <measure type="value" ptr="#e56492f9-7d7b-48b2-a738-673fb75931db">two</measure>-<quantifiedObject id="e56492f9-7d7b-48b2-a738-673fb75931db">class discrimination</quantifiedObject> we also used the AdaBoost algorithm with CART [5] and penalized SVM. Since these are still recently developed algorithms, we briefly summarize their concepts below.</p>
	<p>Let {(x i , y i ) 1≤i≤n } a dataset, where x i ∈ R p is the vector of predictors, and <quantifiedObject id="a92702a3-ded0-4bc5-a545-599163522770">y i</quantifiedObject> ∈ {0, <measure type="list" ptr="#a92702a3-ded0-4bc5-a545-599163522770">1</measure>} is a binary response variable to discriminate. The principle of the AdaBoost algorithm is to re-weight observations that were misclassified by a base classifier (CART in our case). At each step of the procedure, a new classification tree is randomly built, inducing new misclassified sample points whose weights are updated before the following step starts. The method proceeds according to the following algorithm:</p>
	<p>• Step 1 : assign equal weigths to all sample points w [0] i =1/n, ∀i = 1, . . . , n ; • Step 2 : for m=<measure type="value">1</measure>, . . . , M do :</p>
	<p>2. classify the data by resubstitution : determinê g [m] (x i ), i = <measure type="value">1</measure>, . . . , n ;</p>
	<p>A novel observation x is classified by the majority votê f AdaBoost (x), where vote m is weighted by α [m] . In this study AdaBoost was performed for M = <measure type="list">50100200</measure>,  and  on the training set and the parameter value giving the best result was kept.</p>
	<p>Let {(x i , y i ) 1≤i≤n } a training set, where x i ∈ R p is the vector of predictors, and y i ∈ {<measure type="list">−11</measure>, } is the class label. The Support Vector Machine (SVM) algorithm gives the hyperplane H that best splits both groups and that is defined by the equation</p>
	<p>To select a limited number of variables, the term pen λ in (9) can be replaced by a penalization function being singular at the origin and having a continuous first-order derivative [22]. <measure type="value">Two</measure> functions were used in this study :</p>
	<p>where a &gt; <measure type="interval">2</measure> is a tuning parameter. As suggested in [2], a is set by default to <measure type="value">3.7</measure>.</p>
	<p>The optimal λ was chosen by the algorithm in the set <measure type="list">{0.050.100.150.95{0.100.20</measure>, , , . . . , } for L 1 penalization and in , , . . . , <measure type="value">1</measure>} for SCAD penalization. For both penalizations, variables with coefficient |w j | lower than a given were considered useless and removed from the model. In the penalized SVM R package, is set to <measure type="value">0.001</measure> [22].</p>
	<p>The PCA representation of the variables was relevant. As seen on the correlation circle of Figur<quantifiedObject id="fc760a32-c404-4b83-b08a-f7ad50f866ed">e 3, intra-family correlat</quantifiedObject>ions between variables were rather high but inter-family correlations were quite low (with the notable exception of nuts and aeroallergens). Moreover, the total IgE and specific IgE to rAra-h8 did not seem closely related to the other immunoassays, an observation fully validated by clinicians. Indeed, as explained earlier, the level of total IgE is the global measure of this antibody subclass, whereas the specific IgE to rAra-h1, rAra-h2 and rAra-h3 are directed against peanut allergens alone. Also, rAra-h8 is a homologous protein to the birch pollen allergen Bet-v1, sharing about <measure type="value" ptr="#fc760a32-c404-4b83-b08a-f7ad50f866ed">66%</measure> of their amino acid sequences. Thus patients sensitive to both peanut and birch pollen could present high values of specific IgE to rAra-h8 without being allergic to peanuts. These results confirmed clinical observations. Also, the individual representation did not provide supplementary information (data not shown), and no particular interpretation was evident for the PCA axes.</p>
	<p>Here we show the results for the prediction of the first accidental exposure score, the DBPCFC score and the eliciting dose. Tables 3, 4 and 5 give the well-classification rates obtained by combining the classifiers with the <measure type="value">3</measure> different statistical approaches :</p>
	<p><measure type="value">Four</measure>-class study Recall that in what follows, we combined scores 4 and 5 because of the low frequency of score 5. Thus the <measure type="value" ptr="#284eb9ea-dec9-4c81-9cc3-f07c53262b98">four</measure> <quantifiedObject id="284eb9ea-dec9-4c81-9cc3-f07c53262b98">classes considered</quantifiedObject> here are for scores of {1}, {2}, {3}, and {4, 5}. Well-classification rates obtained by fourth-fold cross-validation with each statistical approach are shown in Table 3. The percentage of patients of score 4 who were correctly classified in class 4 is also given. Note that direct application of the classifiers could not have been performed since the number of variables was greater than the size of the learning sets. 5−NN combined with our specific variable selection scheme was the most performant classifier with <measure type="value" ptr="#b0f674e6-12bc-43a0-8e37-b54a16db255a">41%</measure> of well-classified patients, since stepwise logistic regression and penalized SVM did not give better results. Nevertheless all these results remained poor. Replacing variables by factors did not give better results than direct use of the variables. On the <quantifiedObject id="a295a457-f718-494a-98ac-7f4b25f46c2c">whole dataset</quantifiedObject> <measure type="value" ptr="#a295a457-f718-494a-98ac-7f4b25f46c2c">7</measure> variables had a Kruskal-<quantifiedObject id="bf5400d0-0b43-400c-9c55-154cf4c81ee7">Wallis p-value</quantifiedObject> lower than <measure type="interval" ptr="#bf5400d0-0b43-400c-9c55-154cf4c81ee7">0.10</measure> (peanut, walnut, chick pea, pecan nut, broad bean, green pea, cashew nut, ordered by increasing p-value, Table 6) and <measure type="value">8</measure> were retained in the Wilks' lambda selection (chick pea, specific IgE to rAra-h8, green pea, rape seed, peanut, ribwort, total IgE, specific IgE to rAra-h1, Table 7). Thus <measure type="value" ptr="#7f0c357a-49c3-4d5b-95f4-3466f8ae4570">12</measure> <quantifiedObject id="7f0c357a-49c3-4d5b-95f4-3466f8ae4570">different variables</quantifiedObject> were selected in total (<measure type="value" ptr="#eed31318-7c99-4bb9-9e25-7a32ceba2270">3</measure> <quantifiedObject id="eed31318-7c99-4bb9-9e25-7a32ceba2270">immunoassays and</quantifiedObject> <measure type="value" ptr="#5a7bee53-68cf-487f-846e-c90ecd1b9adb">9</measure> <quantifiedObject id="5a7bee53-68cf-487f-846e-c90ecd1b9adb">SPTs</quantifiedObject>). <measure type="value">Two</measure>-class study The methodology used was the same as for the <measure type="value" ptr="#4b7520f3-11fa-40df-a18d-79ee9a2e1298">four</measure>-<quantifiedObject id="4b7520f3-11fa-40df-a18d-79ee9a2e1298">class study</quantifiedObject>. The method which gave the best results for <measure type="value" ptr="#98cdae18-3101-4ec2-a8f0-6503570debe2">two</measure>-<quantifiedObject id="98cdae18-3101-4ec2-a8f0-6503570debe2">class discrimination</quantifiedObject> was 1−NN with factors computed from discriminant variables as predictors (<measure type="value">81%</measure> of well-classified sample points) (Table 3). Of the score 4 patients, <measure type="value">74%</measure> were correctly classified. Contrary to the <measure type="value" ptr="#209add11-ecc6-4242-8c81-02a6b8504265">four</measure>-<quantifiedObject id="209add11-ecc6-4242-8c81-02a6b8504265">class study</quantifiedObject>, the use of factors improved the classification rates compared to the direct use of variables since using selected variables with 1−NN gave <measure type="value" ptr="#63914eeb-7c8a-4151-b2a5-78e9113d592c">79%</measure> of well-classification rate. The other models yielded poor results. Processing the variable selection on the whole dataset gave interesting results. <measure type="value" ptr="#f86608f7-e7a2-4821-900a-09868a5f472a">Eleven</measure> <quantifiedObject id="f86608f7-e7a2-4821-900a-09868a5f472a">different variables</quantifiedObject> were selected to build discriminant factors: peanut, walnut, specific IgE to rAra-h1, specific IgE to rAra-h3, pecan nut for Kruskal-Wallis and peanut, specific IgE to rAra-h1, lupine flour, specific IgE to rAra-h2, ribwort, Dpte, birch, dog epithelia for Wilks' lambda. These immunoassays, as well as SPTs to nuts and legumes, are variables expected by clinicians. This indicates that our selection process seems to detect "useful" variables. More surprisingly, a few SPTs to aeroallergens were also selected. Indeed, these variables are not known to cross-react with peanuts. Note that the discriminant factors will have to be computed these variables to use the best model for further classification.</p>
	<p>The statistical approach used to predict the DBPCFC score was the same as for the first accident score. <measure type="value" ptr="#b796c28a-3740-4bfa-b890-1be67cf49380">Four</measure>-<quantifiedObject id="b796c28a-3740-4bfa-b890-1be67cf49380">class study Scores of</quantifiedObject> 4 and 5 were again grouped together due to the low frequency of score 5. Although applying CART without preselecting variables gave the best results with a <measure type="value" ptr="#9422698c-be4c-48fb-bd3e-059e3a809fd3">38%</measure> <quantifiedObject id="9422698c-be4c-48fb-bd3e-059e3a809fd3">successful classification rate</quantifiedObject>, the overall misclassification error remained high ( Table 4). Note that with the specific variable selection approach, MFA was not performed since only SPTs were entered in the model during cross-validation. Interestingly <measure type="value" ptr="#447172ea-6558-4f0a-b076-6a759393bab7">7</measure> <quantifiedObject id="447172ea-6558-4f0a-b076-6a759393bab7">variables</quantifiedObject> were entered in the classification tree performed on the whole dataset : lupine flour, specific IgE to f13, lentil, total IgE, specific IgE to rAra-h3, <measure type="value">12</measure> grass pollens, specific IgE to rAra-h8, in order of selection. This means that although all variables were available for building a model only a few were considered as useful by the CART algorithm. <measure type="value" ptr="#5cba5dcc-95d9-4585-a749-2f3c8ca57f78">Two</measure>-class <quantifiedObject id="5cba5dcc-95d9-4585-a749-2f3c8ca57f78">study DBPCFC scores</quantifiedObject> can be gathered into <measure type="value" ptr="#afb03d18-0d0a-45c6-9087-ba852ee01f0b">two</measure> <quantifiedObject id="afb03d18-0d0a-45c6-9087-ba852ee01f0b">classes</quantifiedObject> in the same manner as for the first accidental exposure score. Overall, using 3-NN classification with our variable selection scheme offered the best results, with <measure type="value" ptr="#0cfd058f-8d34-43e2-9823-9c869e3053f7">66%</measure> of successfully classified sample points and <measure type="value" ptr="#4b15ee4d-c2f4-4efb-86bb-e1fcc08237b3">33%</measure> of successfully classified severe patients (Table 4). Total IgE was the only immunoassay retained in the model during cross-validation. Thus, no factor was computed. Indeed, assigning the same weight to this single variable as to the other variables did not seem appropriate, because total IgE are not antibodies specifically involved in peanut allergies, but in all allergic reactions. On the whole dataset this resulted in selecting variables lupine flour for Kruskal-Wallis and almond, total IgE, lupine, broad bean, pine nut for Wilks' lambda.</p>
	<p>Before applying directly all the classifiers without selecting variables and performing stepwise logistic regression and penalized SVM, eliciting dose was first converted into a class variable. During cross-validation values were gathered into the partition of minimal Wilks' lambda computed with all available variables. These results were compared to those obtained with our algorithm that simultaneously selects discriminant variables and groups the eliciting dose values in an optimal partition (Section 3.3). This was performed for both <measure type="value" ptr="#b07f91de-630a-470e-ad4c-d97a3671dd89">four</measure>-class (r = 4) and two-class (r = 2) <quantifiedObject id="b07f91de-630a-470e-ad4c-d97a3671dd89">studies</quantifiedObject>. The minimal number of sample points in each class was set to <measure type="value">10</measure>, in order to have class frequencies large enough to perform cross-validation. Note that this process was included in cross-validation. <measure type="value">Four</measure>-class study</p>
	<p>The eliciting dose was correctly predicted for <measure type="value" ptr="#19239d57-1f76-4b22-8a20-a7246fb68a13">39%</measure> of <quantifiedObject id="19239d57-1f76-4b22-8a20-a7246fb68a13">the patients</quantifiedObject> using our algorithm and CART with variables. Moreover, only <measure type="value">52%</measure> of the patients from the lowest eliciting doses group were correctly classified. Other approaches did not give better results (Table 5) . Table 8 The algorithm stopped at step 7 because no additional improvement resulted afterwards. The selected variables were hazelnut, birch, pistachio, cashew nut, green pea, total IgE, pine nut and the bounds were <measure type="list">95, 215, and 500 mg</measure>. The same study was performed with factors as predictors but it did not enhance the model. <measure type="value">Two</measure>-class study Selecting factors of all available variables with our algorithm was the most discriminant model to discriminate the eliciting dose in the <measure type="value" ptr="#48efdfa5-96b8-4a15-85dc-12ac7db99bee">two</measure>-<quantifiedObject id="48efdfa5-96b8-4a15-85dc-12ac7db99bee">class study</quantifiedObject> (<measure type="value" ptr="#70575c08-2356-44e1-90f1-ab0dcab70edb">77%</measure> were successfully classified with 5−NN). It also successfully classified <measure type="value">72%</measure> of the highly reactive patients. The threshold of eliciting dose was <measure type="value">300 mg</measure> with <measure type="value" ptr="#e524e3e1-e6fc-4656-9351-6f64c93fd150">7</measure> <quantifiedObject id="e524e3e1-e6fc-4656-9351-6f64c93fd150">factors selected</quantifiedObject> (Λ = <measure type="value">0.62</measure>). Nevertheless, this model cannot easily be used in practice. Indeed, as mentioned earlier, MFA was performed on all <measure type="value" ptr="#410e48df-3997-42a2-9f67-f20fce7d8e26">34</measure> <quantifiedObject id="410e48df-3997-42a2-9f67-f20fce7d8e26">variables</quantifiedObject>, not just the discriminant variables. This means that to correctly predict the eliciting dose, all variables would have to be measured to compute the factors; this does not seem feasible.</p>
	<p>To the best of our knowledge, this paper presents the first discriminant analysis of DBPCFC score, first accident score, and eliciting dose measurement of peanut allergy severity. Previous studies were aimed at finding links between immunoassays or SPTs and allergy severity, but their statistical analyses were limited to either comparing distributions between groups of patients (using, for instance, the Mann-Whitney test) or to computing linear correlation coefficients [12,19]. In our approach, we used several classification rules to aid in comparing and choosing the optimal and most efficient method. It appeared that in general selecting discriminant variables by a process independent from classification gave better results. In addition, we found that using MFA to compute new predictors was an attractive solution when equalizing the weights of group variables, and we proposed a novel algorithm for simultaneously clustering the levels of ordinal qualitative variables and for selecting discriminant variables. Our work differs from earlier studies in several respects. Previous studies were performed on small sample sizes of <measure type="interval" ptr="#81fd608b-e1d2-413d-a69a-d3a15fcbac06">30 to 40</measure> <quantifiedObject id="81fd608b-e1d2-413d-a69a-d3a15fcbac06">patients [12,19</quantifiedObject>] using a small number of measured variables, which only permitted a limited choice of discriminating predictors. Also, specific IgE to Ara-h1,2,3 were measured by SPTs instead of immunoassays [19] and although a positive response to an SPT does indeed indicate allergen sensitivity, it is still less accurate than immunoassays. There are several scoring methods in the literature to evaluate peanut allergy severity. For example, Hourihane et al. devised a complex <measure type="value">25</measure>-class scoring system combining observed reactions and eliciting doses [12]. A graduation of symptoms was also proposed by Müller [18], but this score is based on allergic reactions in response to bee or wasp venom (and not peanut allergens). Thus, developing a standardized scoring method is still necessary and would facilitate comparison studies from different centers. One possible solution would be comparing the results of Hourihane et al.'s score with the one used in this study using the same cohort of patients. Moreover, the large number of scoring levels in Hourihane et al.'s approach could be reduced by our algorithm. Nevertheless, several potential biases in our study must be noted. First, SPT diameters are relatively imprecise. There is no standard method of measuring SPT reaction since both wheal diameters and areas are popular metrics [19]. Additionally, the score of the first accident can be inaccurate or imprecise since it depends on the medical history of the patient, and hence subject to inaccuracies in the patient's memory which may underestimate symptom severity. Other factors such as medication can affect the first reaction symptoms as well [15,17] yielding a severity score higher than it should be. Finally, the first exposure score is a past event predicted using variables measured during a subsequent DBPCFC. As mentioned in Section 4.2.2, Hourihane et al. also used such a reverse prediction with a community score that was evaluated a posteriori using the record file of the patient [12]. The predictive models used in our study yielded correct classifications for <quantifiedObject id="5a31feaa-de1a-4574-83f4-f23fbb252e2b">the first accidental exposure and DBPCFC of</quantifiedObject> up to <measure type="value" ptr="#5a31feaa-de1a-4574-83f4-f23fbb252e2b">81%</measure> and <measure type="value" ptr="#0f3e3937-48b0-4c0b-af7f-10c803f248d7">66%</measure> for the <measure type="value" ptr="#7e45fcc2-c6bf-48f0-b554-546805a0252f">two</measure>-<quantifiedObject id="7e45fcc2-c6bf-48f0-b554-546805a0252f">class study</quantifiedObject>. Our algorithm also allowed us to group eliciting dose values and to select discriminant predictors, leading to an <measure type="value">77%</measure> classification rate for the <measure type="value" ptr="#f50143f6-7c53-4940-bdcf-168369a2addc">two</measure>-<quantifiedObject id="f50143f6-7c53-4940-bdcf-168369a2addc">class study</quantifiedObject>. This indicates that it is indeed possible to correctly predict peanut allergy severity by measuring well-chosen variables. Considering that all immunoassays of specific IgE were selected once, we also hypothesize that measuring new antibodies to peanut allergens, such as those directed against rArah-6, rArah-7 and rArah-9, will further improve the discriminative power of our models. This also argues for these antibodies playing key roles in the diagnosis of peanut allergy severity. Our variable selection process also offers a new perspective on conducting allergy checkups. Indeed, some unexpected variables appeared several times in our models, such as SPTs to dog epithelia as shown in Figure 4. If future experiments could distinguish the medical relevance of this observation from cross-reactivity, then the importance of these SPTs in discriminating severity would be confirmed. Besides, some SPTs never appeared in our models, such as SPTs to Alternaria or Brazil nut, and thus should no longer be performed in practice when diagnosing peanut allergy severity. Furthermore, some SPTs with proven cross-reactivity to peanuts were retained in our models, such as lupine flour [16], indicating that our results were in line with other medical discoveries. The discriminating models described in this paper are a first step towards a simple, safe and efficient diagnosis of peanut allergy severity by quantifying antibodies. Before being applied in clinical practices, they must first be validated on an independent set of patients. New variables must also be added as additional predictors toward improving successful classification rates. These models could then become practical tools for clinicians. When scoring severity, the clinical test results could be reported online at the allergy vigilance network (Réseau d'allergovigilance, http://www.cicbaa.com/ ), or a simple statistical software could be programmed. Table 3: Results of the discriminant analysis of first accidental exposure score for the <measure type="value" ptr="#bb008c59-19f3-413d-b62a-7400aa9e1d3f">three</measure> <quantifiedObject id="bb008c59-19f3-413d-b62a-7400aa9e1d3f">kinds of</quantifiedObject> variable selection schemes. The best classification method is given for the <measure type="value" ptr="#99cb354d-a81b-443e-bb45-7db53de1392b">four</measure>-class and two-class <quantifiedObject id="99cb354d-a81b-443e-bb45-7db53de1392b">studies</quantifiedObject>. Results are expressed as successful classification rates and as severe patient detection rates. method 4 classes 2 classes no selection x AdaBoost (M = <measure type="value">50</measure>) : <measure type="interval">63%-33%</measure> stepwise logistic regression <measure type="interval" ptr="#e88a5484-14b1-4253-8f58-741ef5bd2960">34-65% 63%</measure><quantifiedObject id="e88a5484-14b1-4253-8f58-741ef5bd2960">%</quantifiedObject>-<measure type="interval" ptr="#37ab0f9e-6a7e-43ee-8b51-1da32ba63080">22.5%</measure> penalized SVM x L 1 : <measure type="value" ptr="#79e7c750-4521-4992-9660-1abaf017ed67">61%</measure>-44% Kruskal-Wallis / Wilks' lambda with variables 5NN : 41%-65% 1NN : 79%-72% Kruskal-Wallis / Wilks' lambda with factors 1NN : 34%-46% 1NN : 81%-74% Table 4: Results of the discriminant analysis of <quantifiedObject id="79e7c750-4521-4992-9660-1abaf017ed67">DBPCFC score</quantifiedObject> for the <measure type="value" ptr="#a22782de-3626-4402-a481-3384e72b4ecf">three</measure> <quantifiedObject id="a22782de-3626-4402-a481-3384e72b4ecf">kinds of</quantifiedObject> variable selection schemes. The best classification method is given for the <measure type="value" ptr="#bb8e68f1-b549-4598-89da-38119949eb29">four</measure>-class and two-class <quantifiedObject id="bb8e68f1-b549-4598-89da-38119949eb29">studies</quantifiedObject>. Results are expressed as successful classification rates and as severe patient detection rates. method 4 classes 2 classes no selection CART : <measure type="interval" ptr="#62900a1c-595f-49d4-855f-2369c15ea9ec">38-44% 2</measure><quantifiedObject id="62900a1c-595f-49d4-855f-2369c15ea9ec">%</quantifiedObject>NN : <measure type="value">64%</measure>-<measure type="interval" ptr="#47d5bd38-40e0-404e-99c2-6247a258da7e">37%35</measure> stepwise logistic regression <quantifiedObject id="47d5bd38-40e0-404e-99c2-6247a258da7e">%</quantifiedObject>-<measure type="interval">32%56</measure> %-<measure type="interval">10%</measure> penalized SVM x L 1 : <measure type="value">62%</measure>-<measure type="interval">24%</measure> Kruskal-Wallis / Wilks' lambda with variables <measure type="value">2</measure>NN : <measure type="interval" ptr="#981bd25e-e331-4af6-a757-4ccca41e82f0">36-52% 3</measure><quantifiedObject id="981bd25e-e331-4af6-a757-4ccca41e82f0">%</quantifiedObject>NN : <measure type="interval" ptr="#41b8f66d-7e14-4656-be02-e3241eba9676">66-33%</measure><quantifiedObject id="41b8f66d-7e14-4656-be02-e3241eba9676">%</quantifiedObject> Kruskal-Wallis / Wilks' lambda with factors x x Table 5: Results of the discriminant analysis of eliciting dose for the <measure type="value" ptr="#6f9d47d7-71e2-42a1-8c32-feca13272ab4">three</measure> <quantifiedObject id="6f9d47d7-71e2-42a1-8c32-feca13272ab4">kinds of</quantifiedObject> variable selection schemes. The best classification method is given for the <measure type="value" ptr="#23f1d37e-f9d2-4fc8-be0f-c7bd021e1fc3">four</measure>-class and two-class <quantifiedObject id="23f1d37e-f9d2-4fc8-be0f-c7bd021e1fc3">studies</quantifiedObject>. Results are expressed as successful classification rates and as severe patient detection rates. method 4 classes 2 classes no selection LDA : <measure type="interval">38%-39% 5</measure>NN : <measure type="interval">69%-62%</measure> stepwise logistic regression <measure type="interval">12%-5%</measure> <measure type="interval">58%-48%</measure> penalized SVM x L 1 : <measure type="value">66%</measure>-<measure type="interval">45%39</measure> algorithm with variables CART : %-<measure type="interval">52% 166%</measure>NN : -<measure type="interval">36%33</measure> algorithm with factors LDA : %-<measure type="interval">34% 577%</measure>NN : -<measure type="interval">72%</measure></p></text>